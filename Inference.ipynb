{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Inference.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnZxIC_w3lAo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e0437dbb-4094-4455-d13f-fdc0bd2417ca"
      },
      "source": [
        "'''if accessing google colab'''\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vFw4amC-FL1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "import keras.backend as K\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import cv2\n",
        "  \n",
        "from __future__ import division\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, concatenate, Conv2D, MaxPooling2D, UpSampling2D, Reshape, core, Dropout\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from keras import backend as K\n",
        "from keras.utils.vis_utils import plot_model as plot\n",
        "from keras.optimizers import SGD\n",
        "from keras.optimizers import *\n",
        "from keras.layers import *  \n",
        "import matplotlib.pyplot as plt\n",
        "try:\n",
        "    from keras_efficientnets import EfficientNetB0 \n",
        "except ModuleNotFoundError:\n",
        "    print('installing keras_efficientnets...')\n",
        "    !pip install keras_efficientnets\n",
        "    from keras_efficientnets import EfficientNetB0\n",
        "def get_result(file):\n",
        "    model_weights = '/content/gdrive/My Drive/final_ct results/finel.hdf5'\n",
        "    segmentation_model_weights = '/content/gdrive/My Drive/final_ct results/weight_lung.hdf5'\n",
        "    def model(weights = model_weights):\n",
        "        net = EfficientNetB0(\n",
        "        include_top=False,\n",
        "        input_shape=(512 ,512 ,3) ,\n",
        "        weights = 'imagenet' ,\n",
        "        dropout_rate = 0.4)\n",
        "        x = keras.layers.Input((512 ,512 ,3))\n",
        "        x_ = keras.layers.Input((512 ,512 ,1))\n",
        "        multiply = keras.layers.Multiply()([x ,x_])\n",
        "        #pre = keras.layers.Lambda(preprocess)(multiply)\n",
        "        final = net(multiply)\n",
        "        conv1 = keras.layers.Conv2D(512 ,kernel_size = (2 ,2) ,strides = 2 ,kernel_initializer='glorot_uniform' ,activation = 'elu')(final)\n",
        "        drop1 = keras.layers.Dropout(0.4)(conv1)\n",
        "        conv2 = keras.layers.Conv2D(512 ,kernel_size = (3 ,3) ,kernel_initializer='glorot_uniform' ,activation = 'elu' ,name = 'pen_ultimate')(drop1)   \n",
        "        pool1 = keras.layers.MaxPooling2D((6 ,6))(conv2)\n",
        "        flatten1 = keras.layers.Flatten()(pool1)\n",
        "        drop2 = keras.layers.Dropout(0.4)(flatten1)\n",
        "        dense1 = keras.layers.Dense(512 ,activation = 'elu')(drop2)\n",
        "        dense1 = keras.layers.Dense(1 ,activation = 'sigmoid' ,name = 'final')(dense1)\n",
        "        classifier = keras.models.Model(inputs = [x ,x_],outputs = dense1)\n",
        "        classifier.load_weights(weights)\n",
        "        return classifier\n",
        "    def BCDU_net_D3(input_size = (256,256,1)):\n",
        "        N = input_size[0]\n",
        "        inputs = Input(input_size) \n",
        "        conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
        "        conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
        "  \n",
        "        pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "        conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
        "        conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
        "        pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "        conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
        "        conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
        "        drop3 = Dropout(0.5)(conv3)\n",
        "        pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "        # D1\n",
        "        conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)     \n",
        "        conv4_1 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
        "        drop4_1 = Dropout(0.5)(conv4_1)\n",
        "    # D2\n",
        "        conv4_2 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(drop4_1)     \n",
        "        conv4_2 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4_2)\n",
        "        conv4_2 = Dropout(0.5)(conv4_2)\n",
        "    # D3\n",
        "        merge_dense = concatenate([conv4_2,drop4_1], axis = 3)\n",
        "        conv4_3 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge_dense)     \n",
        "        conv4_3 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4_3)\n",
        "        drop4_3 = Dropout(0.5)(conv4_3)\n",
        "\n",
        "        up6 = Conv2DTranspose(256, kernel_size=2, strides=2, padding='same',kernel_initializer = 'he_normal')(drop4_3)\n",
        "        up6 = BatchNormalization(axis=3)(up6)\n",
        "        up6 = Activation('relu')(up6)\n",
        "\n",
        "        x1 = Reshape(target_shape=(1, np.int32(N/4), np.int32(N/4), 256))(drop3)\n",
        "        x2 = Reshape(target_shape=(1, np.int32(N/4), np.int32(N/4), 256))(up6)\n",
        "        merge6  = concatenate([x1,x2], axis = 1) \n",
        "        merge6 = ConvLSTM2D(filters = 128, kernel_size=(3, 3), padding='same', return_sequences = False, go_backwards = True,kernel_initializer = 'he_normal' )(merge6)\n",
        "            \n",
        "        conv6 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
        "        conv6 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
        "\n",
        "        up7 = Conv2DTranspose(128, kernel_size=2, strides=2, padding='same',kernel_initializer = 'he_normal')(conv6)\n",
        "        up7 = BatchNormalization(axis=3)(up7)\n",
        "        up7 = Activation('relu')(up7)\n",
        "\n",
        "        x1 = Reshape(target_shape=(1, np.int32(N/2), np.int32(N/2), 128))(conv2)\n",
        "        x2 = Reshape(target_shape=(1, np.int32(N/2), np.int32(N/2), 128))(up7)\n",
        "        merge7  = concatenate([x1,x2], axis = 1) \n",
        "        merge7 = ConvLSTM2D(filters = 64, kernel_size=(3, 3), padding='same', return_sequences = False, go_backwards = True,kernel_initializer = 'he_normal' )(merge7)\n",
        "        \n",
        "        conv7 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
        "        conv7 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
        "\n",
        "        up8 = Conv2DTranspose(64, kernel_size=2, strides=2, padding='same',kernel_initializer = 'he_normal')(conv7)\n",
        "        up8 = BatchNormalization(axis=3)(up8)\n",
        "        up8 = Activation('relu')(up8)    \n",
        "\n",
        "        x1 = Reshape(target_shape=(1, N, N, 64))(conv1)\n",
        "        x2 = Reshape(target_shape=(1, N, N, 64))(up8)\n",
        "        merge8  = concatenate([x1,x2], axis = 1) \n",
        "        merge8 = ConvLSTM2D(filters = 32, kernel_size=(3, 3), padding='same', return_sequences = False, go_backwards = True,kernel_initializer = 'he_normal' )(merge8)    \n",
        "    \n",
        "        conv8 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
        "        conv8 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
        "        conv8 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
        "        conv9 = Conv2D(1, 1, activation = 'sigmoid')(conv8)\n",
        "\n",
        "        model = Model(inputs = inputs, output = conv9)\n",
        "        model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])    \n",
        "        return model\n",
        "    '''Loading segmentation model along with weights'''\n",
        "    seg = BCDU_net_D3(input_size = (512,512,1))\n",
        "    seg.load_weights(segmentation_model_weights)\n",
        "    '''loading the classifier with pretrained weights'''\n",
        "    model = model()\n",
        "    '''Reading the given file and resizing it'''\n",
        "    img_gray = cv2.imread(file ,cv2.IMREAD_GRAYSCALE)\n",
        "    img_gray = cv2.resize(img_gray ,(512 ,512))\n",
        "    img = cv2.imread(file)\n",
        "    img = cv2.resize(img ,(512 ,512))\n",
        "    print('predicting mask....')\n",
        "    mask = seg.predict(np.expand_dims(img_gray ,axis = (0 ,3)))\n",
        "    print('predicting class...')\n",
        "    result = model.predict([np.expand_dims(img ,axis = 0) ,mask])\n",
        "    if result >= 0.5:\n",
        "        print('result : covid')\n",
        "    else:\n",
        "        print('result : non-covid')\n",
        "file = input('Enter the filepath:')\n",
        "get_result(file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwud12XfDRsU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}